
\documentclass[11pt]{article}
\include{template}
\title{Semantic Delta-Debugging} 
\author{
Andrew Coonce, Suhail Shergill, Tristan Ravitch\\
\email{\{coonce, shergill, travitch\}@cs.wisc.edu}
}
\begin{document}
\maketitle

\section{Overview}
The Delta Debugging algorithm introduced by Zeller et al. \cite{dd} works well
for many kinds of inputs. The algorithm is, additionally, simple to understand
and implement. It performs an efficient search over the exponential state space
of input programs to find minimal failing inputs. The algorithm is intentionally
uninformed about the underlying structure of inputs to keep it decoupled from
the semantics of any particular programming language.

Unfortunately, this decoupling can be self-defeating for input files with
rich internal dependencies. As an example, consider the case where the Delta
Debugging algorithm removes a base class from which several others derive in a
C++ source file. Removing, or just breaking, any class in a long inheritance
chain will produce a program that does not compile at all. The Delta Debugging
algorithm is actually designed to tolerate many failures of this form. On the
other hand, there must be at least some successes in order to reduce the input
size by any appreciable factor. In the presence of numerous internal
dependencies, it is likely that no viable reductions will ever emerge. Cases
have been observed where the Delta Debugging algorithm ran for more than three
days and was unable to reduce 700kb input files by more than $20 \%$. In these
situations, the Delta Debugging algorithm only managed to remove whitespace.

This project aims to introduce the simple concept of \emph{dependency} to the
Delta Debugging algorithm to prune impossible inputs from the search space.
This will both reduce the search time and make possible some reductions
that would never emerge under traditional Delta Debugging. The algorithm will
only be altered to take into account the notion of dependency constraints
between character ranges of the input. A different front-end will be required for each
structurally complex input format (C++, Python, Java), but the algorithm itself
will remain ignorant of the semantics any particular input language.

An advantage of basing this work on the Delta Debugging algorithm is that it
does not have to be precise or $100 \%$ accurate. Some amount of robustness
against inaccuracy in the front-end is inherent to the algorithm and the search
will continue around improperly captured dependencies.  The resulting algorithm
will not be in a worse position than the original Delta Debugging algorithm with
regard to spurious syntax errors.  Our goal is only to reduce the number of 
failures over the baseline of Delta Debugging. This structured approach will 
allow us to effectively explore the space of mostly well-formed input programs 
and introduce reductions unavailable to traditional Delta Debugging.


\section{Implementation Details}
We will decouple the actual algorithm, which deals with tracking dependencies
and choosing sections of code to eliminate, from the process of generating said
dependencies.

\begin{itemize}
\item The \emph{front-end} will be responsible for parsing source files and
  generating semantic dependencies between source ranges. We will be working
  with Clang (which is a C/C++ front-end) and would use Clang libraries to
  output structural constraints over C/C++ code.  This approach would generate
  syntactic and semantic dependency constraints over \emph{source ranges}.

\item The constraint in which we have a primary interest is \emph{dependsOn(X,
  Y)} (i.e., construct X depends on construct Y).  We have identified various
  dependencies:

\begin{itemize}
\item{Variable and function \emph{references} depend on their declarations.}
\item{Variable and function \emph{declarations} depend on the declaration of the
type of the variable.}
% \item{Field references depend on the declaration of the variable containing
% the field.}
% \item{Function calls depend on their declarations (again, a subset of the
% first).}
\item{\emph{Typedefs} introduce dependencies between the new and old types.}
\end{itemize}

\item To take advantage of the dependencies, we will investigate new search
  strategies beyond that employed by traditional Delta Debugging.  The goal
  of these strategies is to remove constructs (and their dependencies) in the
  order which most quickly reduces the size of the input.
% \item Once the dependencies have been enumerated the actual algorithm would then
%   adopt a search strategy and start removing constructs (declarations,
%   statements etc.).
  Every time a construct is removed, anything which depends on
  it is also (transitively) removed.  Beyond removal, we may also investigate
  more general transformations of constructs.%  (or more generally 'transformed'
% in some manner).

  We will use a Datalog or Prolog implementation to compute the transitive
  closure of removed constructs based on our generated dependency constraints.
  With some postprocessing, we can reconstruct the remaining program source ranges
  and follow the standard Delta Debugging algorithm in running the debuggee on the
  new input and observing either failures or successes.
% With  based on the dependencies as generated by the front-end will be
%   responsible for aggregating the symbolic ranges of the dependant
%   constructs. After an intermediate step which translates the symbolic source
%   ranges from the dependency graph back to the actual source ranges, we can
%   reconstitute the input with the removed sections and then perform the standard
%   Delta Debugging trick of just trying the input and observing the
%   failure/success mode.

\end{itemize}

\subsection{Search Strategies}
The search strategy can be approached using either common approach:
\begin{itemize}
\item \emph{Top-down}: Start by removing top-level declarations (and things that
  require them). Start removing smaller entities (statements) once no more
  progress can be made there, iterating as necessary.
\item \emph{Bottom-up}: Start removing non-declaration statements aggressively
  as in the search strategy from Zeller \cite{dd}. After no progress can be made, start
  removing larger constructs by working at the next higher stratum.
\end{itemize}
It is not yet clear which method is superior, but the proposed dependency
modifications should make the bottom-up search strategy a more attractive
option than it is in a more traditional, dependency-unaware Delta Debugging.

Delta Debugging typically starts off with a standard binary search. This is
possible under a structured framework, too. To that end we may consider some
heuristics and approximate techniques from graph cutting and image segmentation
literature \cite{nc} in order to keep us from making sweeping changes (eg.,
removing a base class on which all classes may depend).

\subsection{Transformations}
We may be able to do better than simply removing program constructs
if we have dependency (or possibly even richer) information.  Some possibilities are:
% After identifying dependencies between lexical elements, there are several
% things we might like to do to simplify test cases:
\begin{itemize}
% \item Remove element
% \item Replace type with something simpler (struct \rightarrow int)
\item Type simplification.  We could replace complex class types with simple primitives.
\item Function body removal, essentially replacing a function definition with a declaration.
\item Remove a struct, class, or union field.
\item Remove template specializations.
\end{itemize}

Removing entire entities is simple in this framework, since we will record
the source ranges of all constructs.
% The first is easily supported in this framework. With a little work, removing
% struct/class/union fields is pretty simple. Template specializations should also
% be simple.
Removing function bodies could be more difficult because just removing
the curly braces of the body and everything in-between is
insufficient; the body needs to be replaced by a semicolon to produce
a syntactically valid declaration in C.  Something like this is
possible with some extra semantic annotations within the
source ranges. We could specify a list of substitutions for some
ranges that would just be empty for most constructs; for a function
body the list could contain a semicolon.  A related example could be
replacing a complex conditional in a loop with a simple constant.

Type simplification would be difficult to achieve automatically and
will probably be beyond the scope of the current project.


\section{Team Members}
\begin{itemize}
\item{Andrew Coonce}
\item{Suhail Shergill}
\item{Tristan Ravitch}
\end{itemize}

\section{Deliverables Proposed Schedule}
Our deliverables schedule is dictated in part by the program flow and has the
benefit of front-loading most of the code-intensive segments. The project is
viewed as consisting of three main components: Constraint Generation (budget: 4
of our 7 weeks), Querying Framework (budget: 2 weeks), and the Testing Platform
that unifies them (budget: 1 week). While optimistic, this schedule should
provide enough leniency that overruns should be unlikely.
\\
\\
\begin{tabular}{|l|l|l|}
\hline
\multicolumn{3}{|c|}{Timeline} \\
\hline
\multirow{2}{*}{Constraint Generation} & 11/12 &
Parse the source file and determine semantic \\
 & & dependency mappings \\ \hline
\multirow{4}{*}{Querying Framework} & 11/19 & Compose a graph partitioning
strategy that \\
 & & approximates a binary search \\
 & 11/26 & Compute transitive closure of dependency relationships \\
 & & over the search space \\ \hline
\multirow{2}{*}{Testing Platform} & 12/03 & Perform the Symbolic $\rightarrow$
Source Line mappings and \\
 & & generate cases for failure isolation testing \\ \hline
\end{tabular}



\section{Related Work}
There has been some prior work in the area with, perhaps, the one most closely
related to ours being the Hierarchical Delta Debugging algorithm as proposed by
Mishergi et al. \cite{hdd} which works on tree-structured input. However,
while the algorithm can operate on the AST of a program it is unable to
account for dependencies arising from non-ancestral nodes due to declarations.

There have been other extensions to the delta debugging algorithm as well, with
variants such as Artho's Iterative Delta Debugging \cite{idd} directing a search
along the axis of version control commits. Brummayer et al. \cite{smt} used a 
variant of the Hierarchical Delta-Debugging algorithm, using the knowledge of 
formula structures and types to speed up the delta-debugging process on SMT 
formulas.

Our constraint generation step can also be seen as a special case of program
slicing \cite{weiser81} \cite{tip94}. These techniques ease debugging by
removing irrelevant portions of a failing program and can be done either
statically or dynamically (with respect to a concrete run) \cite{agrawal90}. One
strength of our technique is that in combining program slicing with a technique
as failure resistant as delta-debugging we do not need to be as precise in our
analysis.


\section{Future Work}
Our approach can also potentially be extended to other languages eg., Python,
OCaml etc. Python, being dynamically typed, would be challenging since we would
have to perform an interprocedural dataflow analysis to generate the
dependencies. It would still be feasible, however, since we do not need to be
either sound nor complete. At the same time using Python's AST module as a
front-end would make certain things easier too, as we could work at the AST
level and convert it to executable code directly without having to deal with
source ranges, or even program text.

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
