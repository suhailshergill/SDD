
\documentclass[11pt]{article}
\include{template}
\title{Semantic Delta-Debugging} 
\author{
Andrew Coonce, Suhail Shergill, Tristan Ravitch\\
\email{\{coonce, shergill, travitch\}@cs.wisc.edu}
}
\begin{document}
\maketitle

\section{Overview}
The Delta Debugging algorithm introduced by Zeller et al. \cite{dd} works well
for many kinds of inputs. The algorithm is, additionally, simple to understand
and implement. It performs an efficient search over the exponential state space
of input programs to find minimal failing inputs. The algorithm is intentionally
uninformed about the underlying structure of inputs to keep it decoupled from
the semantics of any particular programming language.

Unfortunately, this decoupling can be a serious problem for input files with
many internal dependencies. As an example, consider the case where the Delta
Debugging algorithm removes a base class from which several other derive in a
C++ source file. Removing, or just breaking, any class in a long inheritance
chain will produce a program that does not compile at all. The Delta Debugging
algorithm is actually designed to tolerate many failures of this form. However,
at least some successes are required to reduce the input size by any appreciable
factor. In the presence of many internal dependencies, it is likely that no
viable reductions will ever emerge. Cases have been observed where the Delta
Debugging algorithm has run for three or more days and is unable to reduce a
700kb input file below 600kb (it only managed to remove some whitespace to make
the example even less readable).

This project would aim to introduce the simple concept of \emph{dependency} to the
Delta Debugging algorithm to drastically reduce the number of impossible
inputs. This will both reduce the search time and make possible some reductions
that would never emerge under traditional Delta Debugging. The algorithm will
only be altered to take into account the notion of dependency constraints
between character ranges of the input. A frontend will be required for every
type of structurally complex input (C++, Python, Java), but the algorithm itself
will remain ignorant of any particular input language.

An advantage of basing this work on the Delta Debugging algorithm is that it
does not have to be $100 \%$ accurate or precise. Some amount of robustness
against inaccuracy in the frontend is inherent to the algorithm and the search
will continue around failures. Our goal is only to reduce the number of failures
over the baseline of Delta Debugging. Our structured approach will allow us to
effectively explore the program space along several well-formed axes that delta
debugging cannot touch.


\section{Implementation Details}
We would like to decouple the actual algorithm which deals with the dependencies
from the process of generating said constraints. 
\begin{itemize}
\item{The frontend will be responsible for parsing the source file and coming up with
the semantic dependencies between source ranges. There are two reasonable
choices for creating frontends:}
\begin{itemize}
\item{Instrument clang to output structural constraints over C/C++ code. This
  would be based on recognizing the source ranges of each syntactic construct
  and noting both syntactic and semantic relationships.}
\item{Use the Python AST module. With this approach, we could convert a modified
  AST to executable code directly without having to deal in source ranges.}
\end{itemize}
\item Regardless of the frontend, constraints would be generated based on the
structure of inputs. The primary driving constraint that needs to be generated
is of the form \emph{dependsOn(X, Y)} i.e., constrain X depends on Y. Various
dependencies exist:
\begin{itemize}
\item{Variable references depend on their declarations.}
\item{Variable declarations depend on the declaration of the type of the variable.}
\item{Field references depend on the declaration of the variable containing the field.}
\item{Function calls depend on their declarations (again, a subset of the first).}
\item{Typedefs introduce dependencies between the new type and the old type}
\end{itemize}

\item Once the dependencies have been enumerated the actual algorithm would then
  adopt a search strategy and start removing constructs (declarations,
  statements etc.). Every time a construct is removed anything which depends on
  that is also (transitively) removed (or more generally 'transformed' in some
  manner). A Datalog/Prolog implementation which computes such transitive
  closures based on the dependencies as generated by the frontend will be
  responsible for aggregating the symbolic ranges of the dependant
  constructs. After an intermediate step which translates the symbolic source
  ranges from the dependency graph back to the actual source ranges, we can
  reconstitute the input with the removed sections and then perform the standard
  Delta Debugging trick of just trying the input and observing the
  failure/success mode.

\subsection{Search Strategies}
There are two obvious ways to search the program space:
\begin{itemize}
\item \emph{Top Down}: Start by removing top-level declarations (and things that
  require them). Start removing smaller entities (statements) once no more
  progress can be made there. Iterate as necessary.
\item \emph{Bottom Up}: Start removing non-declaration statements aggressively
  as in the search strategy from Zeller \cite{dd}. After no progress can be made, start
  removing larger constructs by working at the next higher stratum.
\end{itemize}
At this point, it isn't clear which is superior, but bottom up is at least
feasible in this scenario, whereas it is not under standard delta debugging.

Delta debugging typically starts off by approximating binary search. This is
possible under a structured framework, too. To that end we may consider some
heuristics and approximate techniques from graph cutting and image segmentation
literature \cite{nc} in order to keep us from making sweeping changes eg.,
removing a base class on which all classes may depend.

\subsection{Transformations}
After identifying dependencies between lexical elements, there are several
things we might like to do to simplify test cases:
\begin{itemize}
\item Remove element
\item Replace type with something simpler (stuct->int)
\item Remove function body
\item Remove struct/class/union field
\item Remove template specializations
\end{itemize}
The first is easily supported in this framework. With a little work, removing
struct/class/union fields is pretty simple. Template specializations should also
be simple. Removing function bodies could be difficult because just removing the
\{\} and everything in-between is insufficient; the body needs to be replaced by a
semicolon.

Something like this is possible with some work and maybe some extra annotation
within the source ranges. We could specify a list of substitutions for some
ranges that would just be empty most of the time.

Replace by simpler type would be very difficult to achieve automatically and
will probably be beyond the scope of the current project.

\end{itemize}

\subsection{Some thoughts on Python and dynamically typed languages}
Python is interesting in that removing a type is challenging. If class A is
removed, we can easily remove all of its instantiations. We would have to
perform an interprocedural dataflow analysis, however, to find all of the
locations it could have been assigned to. Since we do not need to be precise, we
do not need to make a sound or complete estimate (we can just do a best
effort). This is easier under a typed language since we need only remove all
references to that type.


\section{Team Members}
\begin{itemize}
\item{Andrew Coonce}
\item{Suhail Shergill}
\item{Tristan Ravitch}
\end{itemize}

\section{Deliverables Proposed Schedule}
\begin{tabular}{|l|l|l|}
\hline
\multicolumn{3}{|c|}{Timeline} \\
\hline
Goal 1 & Time & Explanation \\ \hline
\multirow{4}{*}{Goal 2} & Time 1 & Subgoal 1 \\
 & Time 2 & Subgoal 2 \\
 & Time 3 & Subgoal 3 \\
 & Time 4 & Subgoal 4 \\ \hline
\end{tabular}



\section{Related Work}
There has been some prior work in the area with, perhaps, the one most closely
related to ours being the Hierarchical Delta Debugging algorithm as proposed by
Mishergi et al. \cite{hdd} which works on tree-structured input. Specifically
the algorithm can operate on the AST of a program, however, it is unable to
account for dependencies arising from non-ancestral nodes due to class/type
declarations etc.

There have been other extensions to the delta debugging algorithm as well, with
variants such as Artho's Iterative Delta Debugging \cite{idd} directing a search
along the axis of version control commits.

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
